#!/bin/bash
# TÃ¤mÃ¤ skripti kÃ¤ynnistÃ¤Ã¤ kaikki palvelussa olevat kontit
# - Ollama (LLM)
# - rag-vector (Retriever)

# KÃ¤ynnistÃ¤ Ollama taustalle
ollama serve &
echo "â³ Odotetaan ettÃ¤ Ollama kÃ¤ynnistyy..."
sleep 10

# Luo embeddingit
echo "ğŸ”§ Ajetaan embedder.py..."
python rag_vector/embedder.py || { echo "âŒ Embedding epÃ¤onnistui"; exit 1; }
# embedder.py lukee aiemmin tuotetut .jsonl-tiedostot (ne, jotka vectorize.py teki)
# Se purkaa niistÃ¤ tekstin ja embeddingit ja tallentaa ne ChromaDB-tietokantaan
# Tekee Aibotin â€œRetrieverâ€-vaiheen tietovaraston kÃ¤yttÃ¶valmiiksi

# KÃ¤ynnistÃ¤ FastAPI-palvelin
echo "ğŸš€ KÃ¤ynnistetÃ¤Ã¤n FastAPI..."
uvicorn rag_vector.app:app --host 0.0.0.0 --port 8000
# Saa kÃ¤yttÃ¤jÃ¤n kyselyn (/ask, /query tms.).
# Muuntaa kysymyksen embeddingiksi.
# Tekee haun ChromaDB:stÃ¤ (retrieval).
# LÃ¤hettÃ¤Ã¤ haetun kontekstin Ollamalle (augmentation + generation).
# Palauttaa valmiin vastauksen.
