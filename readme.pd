# Aibotti
testisivusto: https://samikoskioamk.github.io/ArcticAIBotti/


✅ 1. Ollama-kontti
Pyörittää LLM-mallia (nomic-embed-text tiedostokäsittelyyn + llama3 vastauksen muodostamiseen).
Palvelee portissa 11434.
Käytetään sekä vektorointiin (embedder.py) että chattiin (app.py tai vastaava).

✅ 2. Vector-kontti (rag_vector)
Sisältää embedder.py-skriptin.
Lataa .jsonl-tiedoston, generoi embeddingit erissä, ja tallentaa ne suoraan ChromaDB:n persistent-kansioon.
Toimii erillään Ollama-kontista mutta käyttää sitä embedding-palveluna.
Kuuntelee ulkoapäin porttia 8000.
On yhteydessä ollama-konttiin rag-network kautta.



Paikallisesti toimiva AI-hakubotti, joka vektorisoi verkkosivun sisällön ja vastaa kysymyksiin Ollama-kielimallin avulla. 
Toteutettu FastAPI + Ollama + HTML/JS-pohjalla.

Ohjeet miten saat pyörimään omalla koneellasi ja omalla datallasi.

1. Kloonaa repositorio
git clone https://github.com/kayttaja/ArcticAIBotti.git
cd ArcticAIBotti

2. Varmista kansiorakenne
docker-compose.yml
VectorDB/          ← Tänne crawlaat omat sivustot .jsonl -tiedostoksi 
rag_vector/
├── Dockerfile
├── app.py
├── embedder.py
├── requirements.txt

3. Käynnistä Ollama-container ensin
docker compose up -d ollama-container

4. Varmista että Ollamassa on oikea malli
docker exec -it ollama-container ollama pull nomic-embed-text

5. Rakenna ja aja rag-vector-kontti (rag_vector kansiosta löytyy)
./rag-container-build.sh

6. Testaa API:
http://localhost:8000/docs

7. Avaa ja testaa HTML-chat
Avaa index.html selaimessa tai Live Serverillä ja testaa kysely.

Todo:
- FastAPI ja embedder omaan konttiinsa. Päivitä nämä ohjeet miten toimitaan.
- Täydelliset ohjeet miten laitat toimimaan omassa Linux-ympäristössä.
- docker myös crawlerille
- web-sivun mobile skaalaus
- data vektorointi tekee automaattisesti domainin perusteella folderin, jonne .jsonl. Päivittää, jos samasta uudempi.


Konttien käynnistys puhtaalta pöydältä:
1) sammuta vanhat
docker compose down

2) rakenna rag-vector uudestaan (varmistaa uudet app.py/requirements)
docker compose build rag-vector --no-cache

3) käynnistä vain Ollama ensin
docker compose up -d ollama-container

4) vedä mallit
docker exec -it ollama-container ollama pull llama3:8b
docker exec -it ollama-container ollama pull nomic-embed-text

5) ingestoi JSONL:t (embedder.py lukee /mnt/e/AI-botti/vektordataJsonl juuresta)
docker compose run --rm rag-vector python embedder.py

6) käynnistä API
docker compose up -d rag-vector

7) testit
curl -s http://localhost:8000/health
curl -G "http://localhost:8000/ask" --data-urlencode "query=Mitä on datamaturiteetti?"


Tai yksinkertaisesti vain:
# jos kontteja entuudestaan pystyssä:
docker compose down

#jos muokkailtu jotain dockerfilejä tai libraryjä requirements.txt filusta tai koodeja muokkailtu
# niin suosittelen kääntämään ensin docker imaget uusiksi niin tulee muutokset mukaan:
docker compose build --no-cache

# Sitten lopuksi kontit pystyyn:
docker compose up -d
