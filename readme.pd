# Aibotti
testisivusto: https://samikoskioamk.github.io/ArcticAIBotti/


✅ 1. Ollama-kontti
Pyörittää LLM-mallia (nomic-embed-text tiedostokäsittelyyn + llama3 vastauksen muodostamiseen).
Palvelee portissa 11434.
Käytetään sekä vektorointiin (embedder.py) että chattiin (app.py tai vastaava).

✅ 2. Vector-kontti (rag_vector)
Sisältää embedder.py-skriptin.
Lataa .jsonl-tiedoston, generoi embeddingit erissä, ja tallentaa ne suoraan ChromaDB:n persistent-kansioon.
Toimii erillään Ollama-kontista mutta käyttää sitä embedding-palveluna.
Kuuntelee ulkoapäin porttia 8000.
On yhteydessä ollama-konttiin rag-network kautta.



Paikallisesti toimiva AI-hakubotti, joka vektorisoi verkkosivun sisällön ja vastaa kysymyksiin Ollama-kielimallin avulla. 
Toteutettu FastAPI + Ollama + HTML/JS-pohjalla.

Ohjeet miten saat pyörimään omalla koneellasi ja omalla datallasi.

1. Kloonaa repositorio
git clone https://github.com/kayttaja/ArcticAIBotti.git
cd ArcticAIBotti

2. Varmista kansiorakenne
docker-compose.yml
VectorDB/          ← sisältää .jsonl -tiedostoja
rag_vector/
├── Dockerfile
├── app.py
├── embedder.py
├── requirements.txt

3. Käynnistä Ollama-container ensin
docker compose up -d ollama-container

4. Varmista että Ollamassa on oikea malli
docker exec -it ollama-container ollama pull nomic-embed-text

5. Rakenna ja aja rag-vector-kontti (rag_vector kansiosta löytyy)
./rag-container-build.sh

6. Testaa API:
http://localhost:8000/docs

7. Avaa ja testaa HTML-chat
Avaa index.html selaimessa tai Live Serverillä ja testaa kysely.

Todo:
- FastAPI ja embedder omaan konttiinsa. Päivitä nämä ohjeet miten toimitaan.
- Täydelliset ohjeet miten laitat toimimaan omassa Linux-ympäristössä.
- docker myös crawlerille
- web-sivun mobile skaalaus
- data vektorointi tekee automaattisesti domainin perusteella folderin, jonne .jsonl. Päivittää, jos samasta uudempi.
